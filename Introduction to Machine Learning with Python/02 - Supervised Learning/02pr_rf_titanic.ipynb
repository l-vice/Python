{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "efbd0065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time magics\n",
    "import time\n",
    "# With the goal above, I will import just what I need.\n",
    "# The model to use is Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# The error metrics will be c-stat (aka ROC/AUC)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# An efficient data structure.\n",
    "import pandas as pd\n",
    "\n",
    "# Import the data\n",
    "titanic = pd.read_csv(\"Datasets/titanic.csv\")\n",
    "y = titanic['Survived']\n",
    "X = titanic.drop('Survived', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "43ea32e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
       "count   891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean    446.000000    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std     257.353842    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min       1.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%     223.500000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%     446.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%     668.500000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max     891.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "222b31d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NA's in 'Age': 177\n",
      "Number of NA's in 'Cabin': 687\n",
      "\n",
      "Complete preview: \n",
      "     PassengerId  Pclass   Name    Sex    Age  SibSp  Parch  Ticket   Fare  \\\n",
      "0          False   False  False  False  False  False  False   False  False   \n",
      "1          False   False  False  False  False  False  False   False  False   \n",
      "2          False   False  False  False  False  False  False   False  False   \n",
      "3          False   False  False  False  False  False  False   False  False   \n",
      "4          False   False  False  False  False  False  False   False  False   \n",
      "..           ...     ...    ...    ...    ...    ...    ...     ...    ...   \n",
      "886        False   False  False  False  False  False  False   False  False   \n",
      "887        False   False  False  False  False  False  False   False  False   \n",
      "888        False   False  False  False   True  False  False   False  False   \n",
      "889        False   False  False  False  False  False  False   False  False   \n",
      "890        False   False  False  False  False  False  False   False  False   \n",
      "\n",
      "     Cabin  Embarked  \n",
      "0     True     False  \n",
      "1    False     False  \n",
      "2     True     False  \n",
      "3    False     False  \n",
      "4     True     False  \n",
      "..     ...       ...  \n",
      "886   True     False  \n",
      "887  False     False  \n",
      "888   True     False  \n",
      "889  False     False  \n",
      "890   True     False  \n",
      "\n",
      "[891 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of NA's in 'Age': {}\".format(sum(X.Age.isna())))\n",
    "print(\"Number of NA's in 'Cabin': {}\".format(sum(X.Cabin.isna())))      \n",
    "\n",
    "print(\"\\nComplete preview: \\n{}\".format(X.isna()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e3516c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>13.002015</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
       "count   891.000000  891.000000  891.000000  891.000000  891.000000  891.000000\n",
       "mean    446.000000    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std     257.353842    0.836071   13.002015    1.102743    0.806057   49.693429\n",
       "min       1.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%     223.500000    2.000000   22.000000    0.000000    0.000000    7.910400\n",
       "50%     446.000000    3.000000   29.699118    0.000000    0.000000   14.454200\n",
       "75%     668.500000    3.000000   35.000000    1.000000    0.000000   31.000000\n",
       "max     891.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have at least two variables with NA values, let's focus on Age now because it's easy to impute.\n",
    "# We will use the mean of 'Age' to impute with mean\n",
    "X['Age'].fillna(X.Age.mean(), inplace = True)\n",
    "\n",
    "# Confirm the code is correct\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5c1f9e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass   Age  SibSp  Parch     Fare\n",
       "0            1       3  22.0      1      0   7.2500\n",
       "1            2       1  38.0      1      0  71.2833\n",
       "2            3       3  26.0      0      0   7.9250\n",
       "3            4       1  35.0      1      0  53.1000\n",
       "4            5       3  35.0      0      0   8.0500"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get just the numeric variables by selecting only the variables that are not \"object\" datatypes.\n",
    "X.dtypes\n",
    "numeric_variables = list(X.dtypes[X.dtypes != 'object'].index)\n",
    "X[numeric_variables].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "75365613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PassengerId seems like a wortless variable, however, it could be valuable. \n",
    "# Therefore, we keep them, lets say a customer bought the ticket early and paid less, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0e803094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-2.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-2.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(oob_score=True, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=n_estimators,-int%2C%20default%3D100\">\n",
       "            n_estimators\n",
       "            <span class=\"param-doc-description\">n_estimators: int, default=100<br><br>The number of trees in the forest.<br><br>.. versionchanged:: 0.22<br>   The default value of ``n_estimators`` changed from 10 to 100<br>   in 0.22.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=criterion,-%7B%22squared_error%22%2C%20%22absolute_error%22%2C%20%22friedman_mse%22%2C%20%22poisson%22%7D%2C%20%20%20%20%20%20%20%20%20%20%20%20%20default%3D%22squared_error%22\">\n",
       "            criterion\n",
       "            <span class=\"param-doc-description\">criterion: {\"squared_error\", \"absolute_error\", \"friedman_mse\", \"poisson\"},             default=\"squared_error\"<br><br>The function to measure the quality of a split. Supported criteria<br>are \"squared_error\" for the mean squared error, which is equal to<br>variance reduction as feature selection criterion and minimizes the L2<br>loss using the mean of each terminal node, \"friedman_mse\", which uses<br>mean squared error with Friedman's improvement score for potential<br>splits, \"absolute_error\" for the mean absolute error, which minimizes<br>the L1 loss using the median of each terminal node, and \"poisson\" which<br>uses reduction in Poisson deviance to find splits.<br>Training using \"absolute_error\" is significantly slower<br>than when using \"squared_error\".<br><br>.. versionadded:: 0.18<br>   Mean Absolute Error (MAE) criterion.<br><br>.. versionadded:: 1.0<br>   Poisson criterion.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;squared_error&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=max_depth,-int%2C%20default%3DNone\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth: int, default=None<br><br>The maximum depth of the tree. If None, then nodes are expanded until<br>all leaves are pure or until all leaves contain less than<br>min_samples_split samples.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=min_samples_split,-int%20or%20float%2C%20default%3D2\">\n",
       "            min_samples_split\n",
       "            <span class=\"param-doc-description\">min_samples_split: int or float, default=2<br><br>The minimum number of samples required to split an internal node:<br><br>- If int, then consider `min_samples_split` as the minimum number.<br>- If float, then `min_samples_split` is a fraction and<br>  `ceil(min_samples_split * n_samples)` are the minimum<br>  number of samples for each split.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=min_samples_leaf,-int%20or%20float%2C%20default%3D1\">\n",
       "            min_samples_leaf\n",
       "            <span class=\"param-doc-description\">min_samples_leaf: int or float, default=1<br><br>The minimum number of samples required to be at a leaf node.<br>A split point at any depth will only be considered if it leaves at<br>least ``min_samples_leaf`` training samples in each of the left and<br>right branches.  This may have the effect of smoothing the model,<br>especially in regression.<br><br>- If int, then consider `min_samples_leaf` as the minimum number.<br>- If float, then `min_samples_leaf` is a fraction and<br>  `ceil(min_samples_leaf * n_samples)` are the minimum<br>  number of samples for each node.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=min_weight_fraction_leaf,-float%2C%20default%3D0.0\">\n",
       "            min_weight_fraction_leaf\n",
       "            <span class=\"param-doc-description\">min_weight_fraction_leaf: float, default=0.0<br><br>The minimum weighted fraction of the sum total of weights (of all<br>the input samples) required to be at a leaf node. Samples have<br>equal weight when sample_weight is not provided.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=max_features,-%7B%22sqrt%22%2C%20%22log2%22%2C%20None%7D%2C%20int%20or%20float%2C%20default%3D1.0\">\n",
       "            max_features\n",
       "            <span class=\"param-doc-description\">max_features: {\"sqrt\", \"log2\", None}, int or float, default=1.0<br><br>The number of features to consider when looking for the best split:<br><br>- If int, then consider `max_features` features at each split.<br>- If float, then `max_features` is a fraction and<br>  `max(1, int(max_features * n_features_in_))` features are considered at each<br>  split.<br>- If \"sqrt\", then `max_features=sqrt(n_features)`.<br>- If \"log2\", then `max_features=log2(n_features)`.<br>- If None or 1.0, then `max_features=n_features`.<br><br>.. note::<br>    The default of 1.0 is equivalent to bagged trees and more<br>    randomness can be achieved by setting smaller values, e.g. 0.3.<br><br>.. versionchanged:: 1.1<br>    The default of `max_features` changed from `\"auto\"` to 1.0.<br><br>Note: the search for a split does not stop until at least one<br>valid partition of the node samples is found, even if it requires to<br>effectively inspect more than ``max_features`` features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=max_leaf_nodes,-int%2C%20default%3DNone\">\n",
       "            max_leaf_nodes\n",
       "            <span class=\"param-doc-description\">max_leaf_nodes: int, default=None<br><br>Grow trees with ``max_leaf_nodes`` in best-first fashion.<br>Best nodes are defined as relative reduction in impurity.<br>If None then unlimited number of leaf nodes.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=min_impurity_decrease,-float%2C%20default%3D0.0\">\n",
       "            min_impurity_decrease\n",
       "            <span class=\"param-doc-description\">min_impurity_decrease: float, default=0.0<br><br>A node will be split if this split induces a decrease of the impurity<br>greater than or equal to this value.<br><br>The weighted impurity decrease equation is the following::<br><br>    N_t / N * (impurity - N_t_R / N_t * right_impurity<br>                        - N_t_L / N_t * left_impurity)<br><br>where ``N`` is the total number of samples, ``N_t`` is the number of<br>samples at the current node, ``N_t_L`` is the number of samples in the<br>left child, and ``N_t_R`` is the number of samples in the right child.<br><br>``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,<br>if ``sample_weight`` is passed.<br><br>.. versionadded:: 0.19</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('bootstrap',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=bootstrap,-bool%2C%20default%3DTrue\">\n",
       "            bootstrap\n",
       "            <span class=\"param-doc-description\">bootstrap: bool, default=True<br><br>Whether bootstrap samples are used when building trees. If False, the<br>whole dataset is used to build each tree.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('oob_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=oob_score,-bool%20or%20callable%2C%20default%3DFalse\">\n",
       "            oob_score\n",
       "            <span class=\"param-doc-description\">oob_score: bool or callable, default=False<br><br>Whether to use out-of-bag samples to estimate the generalization score.<br>By default, :func:`~sklearn.metrics.r2_score` is used.<br>Provide a callable with signature `metric(y_true, y_pred)` to use a<br>custom metric. Only available if `bootstrap=True`.<br><br>For an illustration of out-of-bag (OOB) error estimation, see the example<br>:ref:`sphx_glr_auto_examples_ensemble_plot_ensemble_oob.py`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,<br>:meth:`decision_path` and :meth:`apply` are all parallelized over the<br>trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`<br>context. ``-1`` means using all processors. See :term:`Glossary<br><n_jobs>` for more details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance or None, default=None<br><br>Controls both the randomness of the bootstrapping of the samples used<br>when building trees (if ``bootstrap=True``) and the sampling of the<br>features to consider when looking for the best split at each node<br>(if ``max_features < n_features``).<br>See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=verbose,-int%2C%20default%3D0\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int, default=0<br><br>Controls the verbosity when fitting and predicting.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=warm_start,-bool%2C%20default%3DFalse\">\n",
       "            warm_start\n",
       "            <span class=\"param-doc-description\">warm_start: bool, default=False<br><br>When set to ``True``, reuse the solution of the previous call to fit<br>and add more estimators to the ensemble, otherwise, just fit a whole<br>new forest. See :term:`Glossary <warm_start>` and<br>:ref:`tree_ensemble_warm_start` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=ccp_alpha,-non-negative%20float%2C%20default%3D0.0\">\n",
       "            ccp_alpha\n",
       "            <span class=\"param-doc-description\">ccp_alpha: non-negative float, default=0.0<br><br>Complexity parameter used for Minimal Cost-Complexity Pruning. The<br>subtree with the largest cost complexity that is smaller than<br>``ccp_alpha`` will be chosen. By default, no pruning is performed. See<br>:ref:`minimal_cost_complexity_pruning` for details. See<br>:ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`<br>for an example of such pruning.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=max_samples,-int%20or%20float%2C%20default%3DNone\">\n",
       "            max_samples\n",
       "            <span class=\"param-doc-description\">max_samples: int or float, default=None<br><br>If bootstrap is True, the number of samples to draw from X<br>to train each base estimator.<br><br>- If None (default), then draw `X.shape[0]` samples.<br>- If int, then draw `max_samples` samples.<br>- If float, then draw `max(round(n_samples * max_samples), 1)` samples. Thus,<br>  `max_samples` should be in the interval `(0.0, 1.0]`.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=monotonic_cst,-array-like%20of%20int%20of%20shape%20%28n_features%29%2C%20default%3DNone\">\n",
       "            monotonic_cst\n",
       "            <span class=\"param-doc-description\">monotonic_cst: array-like of int of shape (n_features), default=None<br><br>Indicates the monotonicity constraint to enforce on each feature.<br>  - 1: monotonically increasing<br>  - 0: no constraint<br>  - -1: monotonically decreasing<br><br>If monotonic_cst is None, no constraints are applied.<br><br>Monotonicity constraints are not supported for:<br>  - multioutput regressions (i.e. when `n_outputs_ > 1`),<br>  - regressions trained on data with missing values.<br><br>Read more in the :ref:`User Guide <monotonic_cst_gbdt>`.<br><br>.. versionadded:: 1.4</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-2');</script></body>"
      ],
      "text/plain": [
       "RandomForestRegressor(oob_score=True, random_state=42)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's build our first model. We set the oob_score = True. It is a good idea to increase n_estimators to a number higher than the default.\n",
    "# In this case the oob_predictions will be based on a forest of 33 trees.\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, oob_score=True, random_state=42)\n",
    "\n",
    "# I only use numeric_variables because I have yet to dummy out the categorical variables\n",
    "model.fit(X[numeric_variables], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cdb73426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trailing underscore:  0.14\n"
     ]
    }
   ],
   "source": [
    "# For regression, the oob_score_attribute gives the R^2 based on the oob predictions. We want to use c-stat.\n",
    "# By the way, attributes in sklearn that have a trailing underscore are only available after the model has been trained (fit method ran).\n",
    "# oob = Out of Bag\n",
    "print(\"Trailing underscore: {: .2f}\".format(model.oob_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "024c3abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c-stat:  0.74\n"
     ]
    }
   ],
   "source": [
    "y_oob = model.oob_prediction_\n",
    "print(\"c-stat: {: .2f}\".format(roc_auc_score(y, y_oob))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "35870a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71111111, 0.72413793, 0.02325581, 0.47368421, 0.16666667,\n",
       "       0.34146341, 0.64705882, 0.17647059, 0.52777778, 0.75609756,\n",
       "       0.72222222, 0.29411765, 0.38709677, 0.625     , 0.87096774,\n",
       "       0.46875   , 0.04444444, 0.78571429, 0.41304348, 0.24242424,\n",
       "       0.88571429, 0.64102564, 0.35897436, 0.5       , 0.27777778,\n",
       "       0.05128205, 0.88636364, 0.71428571, 0.46875   , 0.36842105,\n",
       "       0.47368421, 0.23684211, 0.84090909, 0.67647059, 0.82051282,\n",
       "       0.475     , 0.33333333, 0.225     , 0.18421053, 0.53191489,\n",
       "       0.275     , 0.57777778, 0.11904762, 0.90625   , 0.36363636,\n",
       "       0.0625    , 0.61764706, 0.62162162, 0.44186047, 0.16129032,\n",
       "       0.25      , 0.70833333, 0.25      , 0.61290323, 0.36363636,\n",
       "       0.4       , 0.66666667, 0.5       , 1.        , 0.13157895,\n",
       "       0.33333333, 0.2       , 0.76923077, 0.21428571, 0.5       ,\n",
       "       0.25      , 0.36842105, 0.33333333, 0.4516129 , 0.10526316,\n",
       "       0.88888889, 0.13157895, 0.51351351, 0.23076923, 0.34146341,\n",
       "       0.56410256, 0.1       , 0.03030303, 0.97222222, 0.41860465,\n",
       "       0.11428571, 0.07142857, 0.52631579, 0.44444444, 0.54761905,\n",
       "       0.16129032, 0.28571429, 0.        , 0.20512821, 0.        ,\n",
       "       0.06060606, 0.75      , 0.34482759, 0.6       , 0.18421053,\n",
       "       0.        , 0.12820513, 0.26470588, 0.4       , 0.57142857,\n",
       "       0.        , 0.        , 0.58823529, 0.02777778, 0.14893617,\n",
       "       0.02941176, 0.2195122 , 0.30232558, 0.04651163, 0.38095238,\n",
       "       0.1       , 0.51282051, 0.        , 0.32352941, 0.16666667,\n",
       "       0.07317073, 0.2       , 0.59090909, 0.4       , 0.15384615,\n",
       "       0.14285714, 0.        , 0.23333333, 0.28205128, 0.40540541,\n",
       "       0.4       , 0.72727273, 0.08823529, 0.41025641, 0.18604651,\n",
       "       0.        , 0.475     , 0.09090909, 0.14705882, 0.30769231,\n",
       "       0.41463415, 0.57894737, 0.575     , 0.33333333, 0.52272727,\n",
       "       0.79411765, 0.425     , 0.20512821, 0.26315789, 0.42857143,\n",
       "       0.7173913 , 0.375     , 0.3125    , 0.57777778, 0.5       ,\n",
       "       0.17777778, 0.25714286, 0.05263158, 0.10526316, 0.1875    ,\n",
       "       0.2972973 , 0.36842105, 0.06451613, 0.02040816, 0.        ,\n",
       "       0.16666667, 0.28205128, 0.66666667, 0.22857143, 0.15384615,\n",
       "       0.44444444, 0.29787234, 0.1       , 0.3125    , 0.6       ,\n",
       "       0.        , 0.13333333, 0.84090909, 0.21875   , 0.06896552,\n",
       "       0.74285714, 0.25806452, 0.35897436, 0.26190476, 0.13157895,\n",
       "       0.        , 0.41025641, 0.16129032, 0.94594595, 0.76315789,\n",
       "       0.36111111, 0.37142857, 0.40909091, 0.23529412, 0.04878049,\n",
       "       0.05555556, 0.31707317, 0.34285714, 0.97435897, 0.48780488,\n",
       "       0.52173913, 0.64516129, 0.02702703, 0.        , 0.25      ,\n",
       "       0.35483871, 0.02702703, 0.02857143, 0.09090909, 0.65384615,\n",
       "       0.8974359 , 0.47368421, 0.3030303 , 0.51724138, 0.34693878,\n",
       "       0.25714286, 0.45      , 0.2       , 0.42857143, 0.51351351,\n",
       "       0.94444444, 0.09375   , 0.5       , 0.9       , 0.23076923,\n",
       "       0.64516129, 0.29032258, 0.08695652, 0.15151515, 0.81818182,\n",
       "       0.275     , 0.05405405, 0.125     , 0.39534884, 0.21212121,\n",
       "       0.91666667, 0.0625    , 0.10810811, 0.35294118, 0.13953488,\n",
       "       0.        , 0.34482759, 0.92592593, 0.42857143, 0.39473684,\n",
       "       0.43902439, 0.34146341, 0.18181818, 0.06666667, 0.08108108,\n",
       "       0.78125   , 0.27272727, 0.52777778, 0.70588235, 0.23333333,\n",
       "       0.06060606, 0.25714286, 0.13953488, 0.7       , 0.425     ,\n",
       "       0.36363636, 0.77419355, 0.95348837, 0.82352941, 0.34285714,\n",
       "       0.28571429, 0.15909091, 0.9375    , 0.07894737, 0.47619048,\n",
       "       0.11111111, 0.12121212, 0.23684211, 0.4       , 0.86111111,\n",
       "       0.39534884, 0.09756098, 0.42424242, 0.54545455, 0.34146341,\n",
       "       0.54545455, 0.35      , 0.28571429, 0.22580645, 0.2195122 ,\n",
       "       0.15151515, 0.625     , 0.37037037, 0.13953488, 0.43902439,\n",
       "       0.29166667, 0.10810811, 0.25      , 0.22222222, 0.59459459,\n",
       "       0.82926829, 0.75609756, 0.68421053, 0.11904762, 0.07317073,\n",
       "       0.48648649, 0.34883721, 0.96969697, 0.125     , 0.6       ,\n",
       "       0.63636364, 0.72222222, 0.46153846, 0.4       , 0.21875   ,\n",
       "       0.44117647, 0.95121951, 0.70454545, 0.45      , 0.84615385,\n",
       "       0.93548387, 0.80487805, 0.7       , 0.02702703, 0.48780488,\n",
       "       0.42857143, 0.38709677, 0.27272727, 0.60465116, 0.88095238,\n",
       "       0.4047619 , 0.21052632, 0.48648649, 0.66666667, 0.14285714,\n",
       "       0.82222222, 0.29268293, 0.35      , 0.47222222, 0.91428571,\n",
       "       0.55555556, 0.41025641, 0.925     , 0.42857143, 0.725     ,\n",
       "       0.12820513, 0.97297297, 0.925     , 0.12820513, 0.2       ,\n",
       "       0.975     , 0.64444444, 0.53846154, 0.60526316, 0.72727273,\n",
       "       0.29411765, 0.42857143, 0.33333333, 0.9       , 0.45945946,\n",
       "       0.21212121, 0.26315789, 0.51282051, 0.5       , 0.32352941,\n",
       "       0.22222222, 0.85714286, 0.71052632, 0.65625   , 0.74358974,\n",
       "       0.21621622, 0.37142857, 0.39473684, 0.25806452, 0.68571429,\n",
       "       0.51351351, 0.73333333, 0.125     , 0.63636364, 0.77142857,\n",
       "       0.71052632, 0.25714286, 0.45652174, 0.97222222, 0.2972973 ,\n",
       "       0.88571429, 0.21052632, 0.46341463, 0.28888889, 0.55555556,\n",
       "       0.7       , 0.93103448, 0.41025641, 0.45945946, 0.07142857,\n",
       "       0.71428571, 0.35483871, 0.28125   , 0.40740741, 0.575     ,\n",
       "       0.73684211, 0.        , 0.28571429, 0.66666667, 0.30232558,\n",
       "       0.7       , 0.35555556, 0.41666667, 0.5       , 0.41176471,\n",
       "       0.18604651, 0.125     , 0.07142857, 0.52631579, 0.02702703,\n",
       "       0.64516129, 0.27083333, 0.97058824, 0.13333333, 0.02941176,\n",
       "       0.05      , 0.10344828, 1.        , 0.10344828, 0.36842105,\n",
       "       0.17857143, 0.5       , 0.6       , 0.72972973, 0.56521739,\n",
       "       0.10526316, 0.14285714, 0.425     , 0.31818182, 0.36842105,\n",
       "       0.02857143, 0.66666667, 0.86666667, 0.14705882, 0.14893617,\n",
       "       0.72222222, 0.3       , 0.5       , 0.14705882, 0.94871795,\n",
       "       0.88888889, 0.23529412, 0.875     , 0.68571429, 0.56756757,\n",
       "       0.48780488, 0.23684211, 0.21052632, 0.43243243, 0.02777778,\n",
       "       0.89655172, 0.94871795, 0.71052632, 0.75757576, 0.30769231,\n",
       "       0.88636364, 0.45454545, 0.8       , 0.54285714, 0.32142857,\n",
       "       0.10810811, 0.05263158, 0.31428571, 0.45714286, 0.1       ,\n",
       "       0.19512195, 0.08333333, 0.34375   , 0.725     , 0.07692308,\n",
       "       0.03333333, 0.09677419, 0.25      , 0.03571429, 0.90697674,\n",
       "       0.02631579, 0.0952381 , 0.43589744, 0.5       , 0.25      ,\n",
       "       0.76470588, 0.71794872, 0.17241379, 0.38888889, 0.96774194,\n",
       "       0.07317073, 0.07692308, 0.37209302, 0.15      , 0.84782609,\n",
       "       0.07142857, 0.94871795, 0.19354839, 0.02777778, 0.23076923,\n",
       "       0.11764706, 0.23684211, 0.27906977, 0.17948718, 0.02857143,\n",
       "       0.05405405, 0.8125    , 0.17647059, 0.65116279, 0.20588235,\n",
       "       0.05      , 0.3255814 , 0.        , 0.15625   , 0.75      ,\n",
       "       0.90625   , 0.66666667, 0.57142857, 0.36111111, 0.43902439,\n",
       "       0.06060606, 0.06896552, 0.82608696, 0.59375   , 0.21052632,\n",
       "       0.18421053, 0.3125    , 0.3       , 0.66666667, 0.34375   ,\n",
       "       0.88372093, 0.11764706, 0.        , 0.8       , 0.02777778,\n",
       "       0.10714286, 0.60465116, 0.44      , 0.31818182, 0.72727273,\n",
       "       1.        , 0.03030303, 0.2972973 , 0.05263158, 0.08823529,\n",
       "       1.        , 0.79310345, 0.69565217, 0.09677419, 0.81395349,\n",
       "       0.78947368, 0.04081633, 0.02325581, 0.72727273, 0.86486486,\n",
       "       0.06896552, 0.7027027 , 0.48648649, 0.53846154, 0.93939394,\n",
       "       0.84375   , 0.8125    , 0.5       , 0.13513514, 0.23809524,\n",
       "       0.        , 0.3       , 0.72972973, 0.86046512, 0.07894737,\n",
       "       0.35      , 0.16666667, 0.76744186, 0.025     , 0.02941176,\n",
       "       0.27777778, 0.08695652, 0.64864865, 0.30555556, 0.14705882,\n",
       "       0.3125    , 0.6       , 0.66666667, 0.10810811, 0.28      ,\n",
       "       0.18518519, 0.57142857, 0.78378378, 0.2195122 , 0.13513514,\n",
       "       0.5       , 0.66666667, 0.18518519, 0.5483871 , 0.18604651,\n",
       "       0.78947368, 0.3125    , 0.54347826, 0.05405405, 0.        ,\n",
       "       0.        , 0.86486486, 0.        , 0.41176471, 0.56756757,\n",
       "       0.10526316, 0.26829268, 0.04347826, 0.        , 0.76470588,\n",
       "       0.8       , 0.        , 0.51612903, 0.11111111, 0.72972973,\n",
       "       0.2972973 , 0.        , 0.5       , 0.82857143, 0.69230769,\n",
       "       0.02564103, 0.        , 0.125     , 0.21621622, 0.        ,\n",
       "       0.74193548, 0.08108108, 0.26470588, 0.95555556, 0.4       ,\n",
       "       0.2972973 , 0.86842105, 0.17647059, 0.11363636, 0.26829268,\n",
       "       0.33333333, 0.22580645, 0.83783784, 0.02272727, 0.36363636,\n",
       "       0.03703704, 0.        , 0.71875   , 0.08333333, 0.025     ,\n",
       "       0.33333333, 0.41935484, 0.88888889, 0.14285714, 0.46153846,\n",
       "       0.11627907, 0.82051282, 0.19047619, 0.75      , 0.86666667,\n",
       "       1.        , 0.06818182, 0.13953488, 0.30769231, 0.18181818,\n",
       "       0.09375   , 0.675     , 0.13636364, 0.        , 0.4375    ,\n",
       "       0.51612903, 0.23076923, 0.61290323, 0.23255814, 0.75609756,\n",
       "       0.32432432, 0.        , 0.52272727, 0.04347826, 0.02777778,\n",
       "       0.4       , 0.24390244, 0.41463415, 0.02777778, 0.375     ,\n",
       "       0.20512821, 0.83333333, 0.38095238, 0.47058824, 0.1875    ,\n",
       "       0.13888889, 0.15555556, 0.        , 0.08823529, 0.81818182,\n",
       "       0.2       , 0.79411765, 0.175     , 0.02083333, 0.625     ,\n",
       "       0.77272727, 0.        , 0.33333333, 0.02702703, 0.8       ,\n",
       "       0.64285714, 0.94736842, 0.71428571, 0.33333333, 0.35897436,\n",
       "       0.29411765, 0.09375   , 0.29032258, 0.83783784, 0.2       ,\n",
       "       0.55      , 0.75555556, 0.60526316, 0.475     , 0.17948718,\n",
       "       0.62222222, 0.11764706, 0.59259259, 0.5       , 0.12820513,\n",
       "       0.51162791, 0.925     , 0.54285714, 0.19047619, 0.17391304,\n",
       "       0.41860465, 0.86111111, 0.11764706, 0.34883721, 0.10526316,\n",
       "       0.95833333, 0.30952381, 0.51282051, 0.3       , 0.72222222,\n",
       "       0.18181818, 0.37837838, 0.13513514, 0.41666667, 0.4       ,\n",
       "       0.58139535, 0.57692308, 0.08333333, 0.        , 0.        ,\n",
       "       0.025     , 0.15      , 0.85714286, 0.04545455, 0.10714286,\n",
       "       0.21875   , 1.        , 0.68571429, 0.09375   , 0.125     ,\n",
       "       0.65789474, 0.11111111, 0.12195122, 0.83333333, 0.18421053,\n",
       "       0.95238095, 0.75675676, 0.06896552, 0.        , 0.63888889,\n",
       "       0.81818182, 0.24324324, 0.11904762, 0.        , 0.84210526,\n",
       "       0.        , 0.        , 0.30555556, 0.78125   , 0.3030303 ,\n",
       "       0.68571429, 0.23529412, 0.        , 0.03125   , 0.36363636,\n",
       "       0.03703704, 0.16666667, 0.38095238, 0.02325581, 0.36111111,\n",
       "       0.19444444, 0.06060606, 0.8974359 , 0.61764706, 0.81818182,\n",
       "       0.53125   , 0.55263158, 0.69230769, 0.10344828, 0.25641026,\n",
       "       0.27272727, 0.2       , 0.        , 0.93023256, 0.94594595,\n",
       "       0.20588235, 0.70967742, 0.09090909, 0.7       , 0.07142857,\n",
       "       0.11111111, 0.55813953, 0.34210526, 0.1627907 , 0.13157895,\n",
       "       0.17073171, 0.22857143, 0.96774194, 0.55172414, 0.05714286,\n",
       "       0.23076923, 0.02941176, 0.35135135, 0.14285714, 0.76744186,\n",
       "       0.15789474, 0.06818182, 0.13953488, 0.52941176, 0.18181818,\n",
       "       0.        , 0.10526316, 0.5483871 , 0.06818182, 0.13513514,\n",
       "       0.8       , 0.2       , 0.02439024, 0.48648649, 0.125     ,\n",
       "       0.47222222, 0.8974359 , 0.95121951, 0.        , 0.59459459,\n",
       "       0.20512821, 0.97297297, 0.32352941, 0.09375   , 0.14705882,\n",
       "       0.97560976, 0.1025641 , 0.0952381 , 0.29411765, 0.53125   ,\n",
       "       0.13888889, 0.42105263, 0.58823529, 0.09375   , 0.11111111,\n",
       "       0.05882353, 0.10526316, 0.        , 0.80952381, 0.83783784,\n",
       "       0.26666667, 0.30952381, 0.80555556, 0.88571429, 0.85      ,\n",
       "       0.1875    , 0.74358974, 0.78947368, 0.34146341, 0.23333333,\n",
       "       0.19047619, 0.16216216, 0.90322581, 0.05128205, 0.35714286,\n",
       "       0.16666667, 0.5       , 0.75609756, 0.09090909, 0.72727273,\n",
       "       0.05263158, 0.72972973, 0.15384615, 0.17142857, 0.75      ,\n",
       "       0.475     , 0.20512821, 0.15151515, 0.        , 0.84615385,\n",
       "       0.5625    , 0.        , 0.1       , 0.41666667, 0.31034483,\n",
       "       0.12121212, 0.74418605, 0.70588235, 0.28947368, 0.78125   ,\n",
       "       0.33333333])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Out-of-bag predicitons is basically an array of predictions of survival rate for each observation.\n",
    "y_oob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1c51f41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a simple function to show descriptive stats on the categorical variables\n",
    "def describe_categorical(X):\n",
    "    \"\"\"\n",
    "    Just like .describe(), but returns the results for\n",
    "    categorical variables only.\n",
    "    \"\"\"\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(X[X.columns[X.dtypes == \"object\"]].describe().to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c062ccf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>681</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>347082</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "describe_categorical(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "78ee7773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the variables I don't feel like dealing with for this tutorial\n",
    "X.drop([\"Name\", \"Ticket\", \"PassengerId\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6643dbd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       NaN\n",
       "1       C85\n",
       "2       NaN\n",
       "3      C123\n",
       "4       NaN\n",
       "       ... \n",
       "886     NaN\n",
       "887     B42\n",
       "888     NaN\n",
       "889    C148\n",
       "890     NaN\n",
       "Name: Cabin, Length: 891, dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dc385964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the Cabin variable to be only the first letter or None\n",
    "\n",
    "X[\"Cabin\"] = (X[\"Cabin\"].dropna().str[0])\n",
    "X[\"Cabin\"] = X[\"Cabin\"].fillna(\"None\")\n",
    "# Return only the first letter of each observation, if NaN remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e37a623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_variables = ['Sex', 'Cabin', 'Embarked']\n",
    "\n",
    "for variable in categorical_variables:\n",
    "    # Fill missing data with the word \"Missing\"\n",
    "    X[variable].fillna(\"Missing\", inplace=True)\n",
    "    # Create an array of dummies\n",
    "    dummies = pd.get_dummies(X[variable], prefix = variable)\n",
    "    # Update X to include dummies and drop the main variable\n",
    "    X = pd.concat([X, dummies], axis=1)\n",
    "    X.drop([variable], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "81ec699d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>Cabin_C</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>Cabin_None</th>\n",
       "      <th>Cabin_T</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Missing</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at the columns in the dataset\n",
    "def printall(X, max_rows = 10):\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(X.to_html(max_rows=max_rows)))\n",
    "\n",
    "printall(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f67b28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c-stat:  0.86\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=100, oob_score=True, n_jobs=-1,random_state=42)\n",
    "model.fit(X, y)\n",
    "print(\"c-stat: {: .2f}\".format(roc_auc_score(y, model.oob_prediction_)))\n",
    "\n",
    "# This is pretty good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "573913be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable importance measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7d303b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.11384671e-02, 2.38891052e-01, 4.43567267e-02, 2.15831071e-02,\n",
       "       2.15047796e-01, 1.43423437e-01, 1.58822440e-01, 2.95342368e-03,\n",
       "       3.79055011e-03, 6.47116172e-03, 4.30998991e-03, 8.59480266e-03,\n",
       "       1.02403226e-03, 8.12054428e-04, 2.67741854e-02, 6.64265010e-05,\n",
       "       1.06189189e-02, 0.00000000e+00, 6.00379221e-03, 1.53176370e-02])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1c98c526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Simple version that shows all of the variables\n",
    "feature_importances = pd.Series(model.feature_importances_, index = X.columns)\n",
    "feature_importances = feature_importances.sort_values(ascending=True)\n",
    "feature_importances.plot(kind=\"barh\", figsize = (7, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e231e545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_feature_importances(model, feature_names, autoscale=True, headroom=0.05, width=10, summarized_columns=None):\n",
    "    if autoscale:\n",
    "        x_scale = model.feature_importances_.max() + headroom\n",
    "    else:\n",
    "        x_scale = 1\n",
    "    \n",
    "    feature_dict = dict(zip(feature_names, model.feature_importances_))\n",
    "\n",
    "    if summarized_columns:\n",
    "        # some dummy columns need to be summarized\n",
    "        for col_name in summarized_columns:\n",
    "            # sum all the features that contain col_name, store in temp sum_value\n",
    "            sum_value = sum(x for i, x in feature_dict.iteritems() if col_name in i )\n",
    "\n",
    "            # now remove all keys that are part of col_name\n",
    "            keys_to_remove = [i for i in feature_dict.keys() if col_name in i]\n",
    "            for i in keys_to_remove:\n",
    "                feature_dict.pop(i)\n",
    "            # lastly, read the summarized field\n",
    "            feature_dict[col_name] = sum_value\n",
    "    \n",
    "    results = pd.Series(feature_dict.value(), index = feature_dict.keys())\n",
    "    results.sort(axis = 1)\n",
    "    results.plot(kind=\"barh\", figsize=(width, len(results)/4), xlim=(0, x_scale))\n",
    "\n",
    "graph_feature_importances(model, X.columns, summarized_columns=categorical_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fe453040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "# Parameter tests\n",
    "print(X.dtypes)\n",
    "print(y.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "76201924",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Braund, Mr. Owen Harris'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_16440\\2921209504.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      6\u001b[39m     start = time.perf_counter()\n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m     model = RandomForestRegressor(\u001b[32m1000\u001b[39m, oob_score=\u001b[38;5;28;01mTrue\u001b[39;00m, n_jobs=jobs, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m      9\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     model.fit(X, y)\n\u001b[32m     11\u001b[39m \n\u001b[32m     12\u001b[39m     elapsed = time.perf_counter() - start\n\u001b[32m     13\u001b[39m     print(f\"n_jobs = {jobs}: {elapsed:.2f} seconds\")\n",
      "\u001b[32mc:\\Users\\DELL\\AppData\\Local\\Python\\pythoncore-3.14-64\\Lib\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1332\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m                 )\n\u001b[32m   1335\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[32mc:\\Users\\DELL\\AppData\\Local\\Python\\pythoncore-3.14-64\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    355\u001b[39m         \u001b[38;5;66;03m# Validate or convert input data\u001b[39;00m\n\u001b[32m    356\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[32m    357\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"sparse multilabel-indicator for y is not supported.\"\u001b[39m)\n\u001b[32m    358\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         X, y = validate_data(\n\u001b[32m    360\u001b[39m             self,\n\u001b[32m    361\u001b[39m             X,\n\u001b[32m    362\u001b[39m             y,\n",
      "\u001b[32mc:\\Users\\DELL\\AppData\\Local\\Python\\pythoncore-3.14-64\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2915\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"estimator\"\u001b[39m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m check_y_params:\n\u001b[32m   2916\u001b[39m                 check_y_params = {**default_check_params, **check_y_params}\n\u001b[32m   2917\u001b[39m             y = check_array(y, input_name=\u001b[33m\"y\"\u001b[39m, **check_y_params)\n\u001b[32m   2918\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2919\u001b[39m             X, y = check_X_y(X, y, **check_params)\n\u001b[32m   2920\u001b[39m         out = X, y\n\u001b[32m   2921\u001b[39m \n\u001b[32m   2922\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m check_params.get(\u001b[33m\"ensure_2d\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[32mc:\\Users\\DELL\\AppData\\Local\\Python\\pythoncore-3.14-64\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1310\u001b[39m         raise ValueError(\n\u001b[32m   1311\u001b[39m             f\"{estimator_name} requires y to be passed, but the target y is None\"\n\u001b[32m   1312\u001b[39m         )\n\u001b[32m   1313\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m1314\u001b[39m     X = check_array(\n\u001b[32m   1315\u001b[39m         X,\n\u001b[32m   1316\u001b[39m         accept_sparse=accept_sparse,\n\u001b[32m   1317\u001b[39m         accept_large_sparse=accept_large_sparse,\n",
      "\u001b[32mc:\\Users\\DELL\\AppData\\Local\\Python\\pythoncore-3.14-64\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1019\u001b[39m                         )\n\u001b[32m   1020\u001b[39m                     array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1021\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1022\u001b[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1024\u001b[39m                 raise ValueError(\n\u001b[32m   1025\u001b[39m                     \u001b[33m\"Complex data not supported\\n{}\\n\"\u001b[39m.format(array)\n\u001b[32m   1026\u001b[39m                 ) \u001b[38;5;28;01mfrom\u001b[39;00m complex_warning\n",
      "\u001b[32mc:\\Users\\DELL\\AppData\\Local\\Python\\pythoncore-3.14-64\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    874\u001b[39m         \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    875\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    876\u001b[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    877\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    879\u001b[39m \n\u001b[32m    880\u001b[39m         \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
      "\u001b[32mc:\\Users\\DELL\\AppData\\Local\\Python\\pythoncore-3.14-64\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   2167\u001b[39m             )\n\u001b[32m   2168\u001b[39m         values = self._values\n\u001b[32m   2169\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2170\u001b[39m             \u001b[38;5;66;03m# Note: branch avoids `copy=None` for NumPy 1.x support\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2171\u001b[39m             arr = np.asarray(values, dtype=dtype)\n\u001b[32m   2172\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2173\u001b[39m             arr = np.array(values, dtype=dtype, copy=copy)\n\u001b[32m   2174\u001b[39m \n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: 'Braund, Mr. Owen Harris'"
     ]
    }
   ],
   "source": [
    "# TBC\n",
    "\n",
    "# n_jobs comparison [1, -1]\n",
    "\n",
    "for jobs in [1, -1]:\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    model = RandomForestRegressor(1000, oob_score=True, n_jobs=jobs, random_state=42)\n",
    "\n",
    "    model.fit(X, y)\n",
    "\n",
    "    elapsed = time.perf_counter() - start\n",
    "    print(f\"n_jobs = {jobs}: {elapsed:.2f} seconds\")\n",
    "\n",
    "# TBC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
